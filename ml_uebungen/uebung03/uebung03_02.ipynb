{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Ãœbung 03 - Aufgabe 2"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: progressbar2 in /home/ekrem/.pyenv/versions/3.6.12/envs/htwg-ml/lib/python3.6/site-packages (3.53.1)\r\n",
      "Requirement already satisfied: six in /home/ekrem/.pyenv/versions/3.6.12/envs/htwg-ml/lib/python3.6/site-packages (from progressbar2) (1.15.0)\r\n",
      "Requirement already satisfied: python-utils>=2.3.0 in /home/ekrem/.pyenv/versions/3.6.12/envs/htwg-ml/lib/python3.6/site-packages (from progressbar2) (2.4.0)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install progressbar2\n",
    "import os\n",
    "import wget\n",
    "import tarfile\n",
    "import re\n",
    "import progressbar\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "Software versions\nPython 3.6.12 64bit [GCC 9.3.0]\nIPython 7.16.1\nOS Linux 5.4.0 54 generic x86_64 with debian bullseye sid\nnumpy 1.18.5\nsklearn 0.23.2\nThu Nov 26 14:38:28 2020 CET",
      "text/html": "<table><tr><th>Software</th><th>Version</th></tr><tr><td>Python</td><td>3.6.12 64bit [GCC 9.3.0]</td></tr><tr><td>IPython</td><td>7.16.1</td></tr><tr><td>OS</td><td>Linux 5.4.0 54 generic x86_64 with debian bullseye sid</td></tr><tr><td>numpy</td><td>1.18.5</td></tr><tr><td>sklearn</td><td>0.23.2</td></tr><tr><td colspan='2'>Thu Nov 26 14:38:28 2020 CET</td></tr></table>",
      "text/latex": "\\begin{tabular}{|l|l|}\\hline\n{\\bf Software} & {\\bf Version} \\\\ \\hline\\hline\nPython & 3.6.12 64bit [GCC 9.3.0] \\\\ \\hline\nIPython & 7.16.1 \\\\ \\hline\nOS & Linux 5.4.0 54 generic x86\\_64 with debian bullseye sid \\\\ \\hline\nnumpy & 1.18.5 \\\\ \\hline\nsklearn & 0.23.2 \\\\ \\hline\n\\hline \\multicolumn{2}{|l|}{Thu Nov 26 14:38:28 2020 CET} \\\\ \\hline\n\\end{tabular}\n",
      "application/json": {
       "Software versions": [
        {
         "module": "Python",
         "version": "3.6.12 64bit [GCC 9.3.0]"
        },
        {
         "module": "IPython",
         "version": "7.16.1"
        },
        {
         "module": "OS",
         "version": "Linux 5.4.0 54 generic x86_64 with debian bullseye sid"
        },
        {
         "module": "numpy",
         "version": "1.18.5"
        },
        {
         "module": "sklearn",
         "version": "0.23.2"
        }
       ]
      }
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%reload_ext version_information\n",
    "%version_information numpy, sklearn"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Aufgabe a.)\n",
    "### Datensatz herunterladen"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "newsgroup20_tgz = '20news-18828.tar.gz'\n",
    "newsgroup20_folder = os.path.join(os.getcwd(), '20news-18828')\n",
    "\n",
    "if not os.path.isdir(newsgroup20_folder):\n",
    "    print(\"Downloading file...\\n\")\n",
    "\n",
    "    if not os.path.isfile(newsgroup20_tgz):\n",
    "        wget.download('http://qwone.com/~jason/20Newsgroups/20news-18828.tar.gz', newsgroup20_tgz)\n",
    "\n",
    "    os.mkdir(newsgroup20_folder)\n",
    "\n",
    "    with tarfile.open(newsgroup20_tgz) as tar:\n",
    "        tar.extractall(path=os.getcwd())\n",
    "\n",
    "    print(\"Files extracted\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Aufgabe b.)\n",
    "### Stringvektoren & Labels vorbereiten"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def strip_header(text):\n",
    "    _befor, _blankline, after = text.partition('\\n\\n')\n",
    "    return after"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of vectors: 3387\n",
      "Number of labels: 3387\n"
     ]
    }
   ],
   "source": [
    "newsgroups = [\"alt.atheism\", \"comp.graphics\", \"sci.space\", \"talk.religion.misc\"]\n",
    "raw_data = []\n",
    "labels = []\n",
    "\n",
    "for newsgroup in newsgroups:\n",
    "    for subdir, _, files in os.walk(os.path.join(newsgroup20_folder, newsgroup)):\n",
    "        for file in files:\n",
    "            labels.append(newsgroup)\n",
    "            with open(os.path.join(subdir, file), 'r', encoding=\"ISO-8859-1\") as f:\n",
    "                s = strip_header(f.read())\n",
    "                raw_data.append(s)\n",
    "\n",
    "print(\"Number of vectors:\", len(raw_data))\n",
    "print(\"Number of labels:\", len(labels))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Aufgabe c.)\n",
    "### Tokens generieren"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "stripped_data = [strip_header(text) for text in raw_data]\n",
    "data_regex = [re.compile(r\"(?u)\\b[a-zA-Z]+\\b\").findall(s.lower()) for s in stripped_data]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique tokens: 32122\n"
     ]
    }
   ],
   "source": [
    "unique_tokens = []\n",
    "for tokens in data_regex:\n",
    "    unique_tokens.extend(tokens)\n",
    "\n",
    "unique_tokens = list(set(unique_tokens))\n",
    "unique_tokens.sort()\n",
    "print(\"Number of unique tokens: {}\".format(len(unique_tokens)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "FEATURE_VECTORS_PATH = os.path.join(os.getcwd(), 'feature_vectors.npy')\n",
    "\n",
    "def generate_feature_vector(_data, _tokens):\n",
    "    _feature_vectors = np.zeros(shape=(len(_data), len(_tokens)))\n",
    "\n",
    "    with progressbar.ProgressBar(max_value=len(_data)) as bar:\n",
    "        for i, text in enumerate(_data):\n",
    "            for j, token in enumerate(_tokens):\n",
    "                _feature_vectors[i][j] = text.count(token)\n",
    "            bar.update(i)\n",
    "\n",
    "    _feature_vectors = np.asarray(_feature_vectors, dtype=np.int)\n",
    "\n",
    "    np.save(FEATURE_VECTORS_PATH, _feature_vectors)\n",
    "\n",
    "    return _feature_vectors"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Tokens & Merkmalsvektor generieren und speichern"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading saved feature vectors.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    feature_vectors = np.load(FEATURE_VECTORS_PATH)\n",
    "    print(\"Loading saved feature vectors.\")\n",
    "except IOError:\n",
    "    print(\"No saved feature vectors found. Generating new ones..\")\n",
    "    feature_vectors = generate_feature_vector(data_regex, unique_tokens)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Aufgabe d.)\n",
    "### Train- und Testset aufteilen"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete-Set shape: (3387, 32122)\n",
      "Complete-Set labels shape: (3387,)\n",
      "\n",
      "Training-Set shape: (2032, 32122)\n",
      "Training-Set labels shape: (2032,)\n",
      "\n",
      "Test-Set shape: (1355, 32122)\n",
      "Test-Set labels shape: (1355,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(feature_vectors, labels, test_size=0.4, random_state=42)\n",
    "\n",
    "print(\"Complete-Set shape:\", np.shape(feature_vectors))\n",
    "print(\"Complete-Set labels shape:\", np.shape(labels))\n",
    "print()\n",
    "print(\"Training-Set shape:\", np.shape(X_train))\n",
    "print(\"Training-Set labels shape:\", np.shape(y_train))\n",
    "print()\n",
    "print(\"Test-Set shape:\", np.shape(X_test))\n",
    "print(\"Test-Set labels shape:\", np.shape(y_test))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Trainieren des multinomialen naiven Bayes-Klassifikators"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "Ni = {}\n",
    "nij = {}\n",
    "pij = {}\n",
    "\n",
    "for newsgroup in newsgroups:\n",
    "    Ni[newsgroup] = 0\n",
    "    nij[newsgroup] = 0\n",
    "    pij[newsgroup] = 0\n",
    "\n",
    "for x, y in zip(X_train, y_train):\n",
    "    Ni[y] += x.sum()\n",
    "    nij[y] += x\n",
    "\n",
    "for newsgroup in newsgroups:\n",
    "    pij[newsgroup] = (nij[newsgroup] + 1) / (Ni[newsgroup] + len(unique_tokens))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Bestimmung von korrekter Klassifikationen im Testdatensatz"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct classification: 1084/1355\n",
      "Score: 80.0%\n"
     ]
    }
   ],
   "source": [
    "corrects = np.full(shape=(len(X_test)), fill_value=False)\n",
    "\n",
    "for i, lable in enumerate(y_test):\n",
    "    max_p = -np.inf\n",
    "    max_newsgroup = \"\"\n",
    "\n",
    "    for newsgroup in newsgroups:\n",
    "        p = np.sum(np.log(pij[newsgroup]) * X_test[i])\n",
    "\n",
    "        if p > max_p:\n",
    "            max_p = p\n",
    "            max_newsgroup = newsgroup\n",
    "\n",
    "    corrects[i] = (lable==max_newsgroup)\n",
    "\n",
    "print(\"Correct classification: {}/{}\".format(corrects.sum(), len(X_test)))\n",
    "print(\"Score: {}%\".format(np.round((corrects.sum() / len(X_test))*100, decimals=2)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Verwendung von sklearn Bibliothek"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 79.48%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "mnb = MultinomialNB()\n",
    "mnb.fit(X_train, y_train)\n",
    "score = mnb.score(X_test, y_test)\n",
    "\n",
    "print(\"Score: {}%\".format(np.round(score*100, decimals=2)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}